{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de13a3df",
   "metadata": {},
   "source": [
    "### confusion matrix\n",
    "A confusion matrix is a table that summarizes the performance of a classification model by showing the counts of true positives, true negatives, false positives, and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d4cda",
   "metadata": {},
   "source": [
    "1. Provides a detailed breakdown of the model's predictions.\n",
    "2. Helps identify where the model is making errors (e.g., false positives or false negatives).\n",
    "3. Useful for calculating other metrics like accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1832edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cae8ed84",
   "metadata": {},
   "source": [
    "### F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35cf11a",
   "metadata": {},
   "source": [
    "The F1-score is the harmonic mean of precision and recall. It balances the trade-off between these two metrics and is particularly useful when dealing with imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24fee7",
   "metadata": {},
   "source": [
    "Formula:\n",
    "   ### F1-Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "Where:\n",
    "\n",
    "Precision = TP / (TP + FP): Proportion of correctly predicted positives out of all predicted positives.\n",
    "\n",
    "Recall = TP / (TP + FN): Proportion of correctly predicted positives out of all actual positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a61d39",
   "metadata": {},
   "source": [
    "> Uses:\n",
    "* Useful when you need a balance between precision and recall.\n",
    "* Helps evaluate the model's performance in scenarios where false positives or false negatives are costly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4e83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe1240bf",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f16e26",
   "metadata": {},
   "source": [
    "The classification report is a comprehensive summary of a classification model's performance. It includes metrics like precision, recall, F1-score, and support (number of true instances for each class)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373c103",
   "metadata": {},
   "source": [
    "> Uses:\n",
    "* Provides a detailed overview of the model's performance for each class.\n",
    "* Useful for multi-class classification problems.\n",
    "* Helps identify which classes the model is performing well on and which need improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea4ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
